{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Translation_Project_attention_LSTM_en_ru.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"6e7ddad4551e411ebc7022e220710b71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_491145053af84ce18d2cabedca49280f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b744bc65c968419dbf507b156357dd89","IPY_MODEL_212cc8cd1a9f4894b11d56329341c8e1"]}},"491145053af84ce18d2cabedca49280f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b744bc65c968419dbf507b156357dd89":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34a534950fd64acf8b9684245b5623cf","_dom_classes":[],"description":" 40%","_model_name":"FloatProgressModel","bar_style":"","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":4,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f77274caad944d61bd831b8f9271804b"}},"212cc8cd1a9f4894b11d56329341c8e1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f316e3a790204517a1742cdeccb297e2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 4/10 [31:14&lt;46:51, 468.52s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c6bded63dbc143bc8055404e36dffe04"}},"34a534950fd64acf8b9684245b5623cf":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f77274caad944d61bd831b8f9271804b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f316e3a790204517a1742cdeccb297e2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c6bded63dbc143bc8055404e36dffe04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"i2Ko1khAESrf","executionInfo":{"status":"ok","timestamp":1626353991051,"user_tz":-180,"elapsed":7467,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchtext\n","from torchtext.legacy.data import Field, BucketIterator\n","\n","import spacy\n","from tqdm.notebook import tqdm\n","import tqdm\n","import random\n","import math\n","import time\n","import numpy as np\n","\n","import matplotlib\n","matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from IPython.display import clear_output\n","\n","from nltk.tokenize import WordPunctTokenizer\n","from torch.nn import functional as F"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeyNXU5GQ-LJ","executionInfo":{"status":"ok","timestamp":1626353993952,"user_tz":-180,"elapsed":242,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["SEED = 666\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvr0cndHF7od","executionInfo":{"status":"ok","timestamp":1626354001311,"user_tz":-180,"elapsed":249,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"1fb9cfcc-c987-4ec0-e4e4-796ff8fb2d3b"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDopBvyWaXEQ","executionInfo":{"status":"ok","timestamp":1626354017737,"user_tz":-180,"elapsed":14856,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"702ae34b-49b2-41db-8f24-a8f23703d3f8"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvHcv5trG8UU","executionInfo":{"status":"ok","timestamp":1626354019670,"user_tz":-180,"elapsed":673,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"259aa435-c713-4476-e77b-8146f6d6333c"},"source":["!ls '/content/drive/MyDrive/Colab Notebooks/NLP'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["simle_LSTM_last.pt   Translation_Project_attention_LSTM.ipynb\n","simple_LSTM_bleu.pt  Translation_Project_simple_LSTM.ipynb\n","simple_LSTM.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rxi_ltKkKmw_","executionInfo":{"status":"ok","timestamp":1626354030664,"user_tz":-180,"elapsed":1798,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"503f204f-23e5-42dd-9814-8039c7e98c4b"},"source":["!wget https://drive.google.com/uc?id=1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_ -O data.txt"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2021-07-15 13:00:33--  https://drive.google.com/uc?id=1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_\n","Resolving drive.google.com (drive.google.com)... 74.125.195.113, 74.125.195.102, 74.125.195.101, ...\n","Connecting to drive.google.com (drive.google.com)|74.125.195.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-14-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/3m3g0ko1fb1rvnj2ns3fj3etmig11bdq/1626354000000/16549096980415837553/*/1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_ [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-07-15 13:00:34--  https://doc-14-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/3m3g0ko1fb1rvnj2ns3fj3etmig11bdq/1626354000000/16549096980415837553/*/1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_\n","Resolving doc-14-00-docs.googleusercontent.com (doc-14-00-docs.googleusercontent.com)... 74.125.20.132, 2607:f8b0:400e:c07::84\n","Connecting to doc-14-00-docs.googleusercontent.com (doc-14-00-docs.googleusercontent.com)|74.125.20.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/plain]\n","Saving to: ‘data.txt’\n","\n","data.txt                [  <=>               ]  12.31M  47.2MB/s    in 0.3s    \n","\n","2021-07-15 13:00:34 (47.2 MB/s) - ‘data.txt’ saved [12905334]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jDbsLi5YJq9P","executionInfo":{"status":"ok","timestamp":1626354083001,"user_tz":-180,"elapsed":321,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["tokenizer_W = WordPunctTokenizer()\n","\n","def tokenize_ru(x, tokenizer=WordPunctTokenizer()):\n","    return tokenizer.tokenize(x.lower())\n","\n","def tokenize_en(x, tokenizer=WordPunctTokenizer()):\n","    return tokenizer.tokenize(x.lower())"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxjRcQAbJwwI","executionInfo":{"status":"ok","timestamp":1626354090302,"user_tz":-180,"elapsed":2191,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["SRC = Field(tokenize=tokenize_en,\n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","TRG = Field(tokenize=tokenize_ru,\n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","\n","dataset = torchtext.legacy.data.TabularDataset(\n","    path='data.txt',\n","    format='tsv',\n","    fields=[('src', SRC), ('trg', TRG)]\n",")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHliJlHxJw9g","executionInfo":{"status":"ok","timestamp":1626354150242,"user_tz":-180,"elapsed":232,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"e0ef326c-94a9-47cb-ae9e-09d3298bdb47"},"source":["print(len(dataset.examples))\n","print(dataset.examples[0].src)\n","print(dataset.examples[0].trg)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["50000\n","['cordelia', 'hotel', 'is', 'situated', 'in', 'tbilisi', ',', 'a', '3', '-', 'minute', 'walk', 'away', 'from', 'saint', 'trinity', 'church', '.']\n","['отель', 'cordelia', 'расположен', 'в', 'тбилиси', ',', 'в', '3', 'минутах', 'ходьбы', 'от', 'свято', '-', 'троицкого', 'собора', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ITHVChNxLAe-","executionInfo":{"status":"ok","timestamp":1626354151682,"user_tz":-180,"elapsed":8,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"88cee28a-2245-44c5-a6d1-1e372f4e6e07"},"source":["train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n","\n","print(f\"Number of training examples: {len(train_data.examples)}\")\n","print(f\"Number of validation examples: {len(valid_data.examples)}\")\n","print(f\"Number of testing examples: {len(test_data.examples)}\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Number of training examples: 40000\n","Number of validation examples: 2500\n","Number of testing examples: 7500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFgcavqGLHT-","executionInfo":{"status":"ok","timestamp":1626354156437,"user_tz":-180,"elapsed":608,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["SRC.build_vocab(dataset, min_freq = 2)\n","TRG.build_vocab(dataset, min_freq = 2)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgPWlOaHLI_v","executionInfo":{"status":"ok","timestamp":1626354167072,"user_tz":-180,"elapsed":291,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"8de46f6f-910f-4cd5-e4f4-95ca76eca1ec"},"source":["print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n","print(f\"Unique tokens in target (ru) vocabulary: {len(TRG.vocab)}\")"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Unique tokens in source (en) vocabulary: 11778\n","Unique tokens in target (ru) vocabulary: 16483\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dq_JbomULJMv","executionInfo":{"status":"ok","timestamp":1626354170676,"user_tz":-180,"elapsed":297,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"72de459f-727f-455c-a469-bb797ad5607d"},"source":["print(vars(train_data.examples[9]))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["{'src': ['there', 'is', 'a', 'concierge', 'service', 'and', '24', '-', 'hour', 'front', 'desk', '.'], 'trg': ['гостям', 'предоставляются', 'услуги', 'консьержа', 'и', 'круглосуточной', 'стойки', 'регистрации', '.']}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4qGOkfOHGEa8","executionInfo":{"status":"ok","timestamp":1626354182557,"user_tz":-180,"elapsed":234,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["def _len_sort_key(x):\n","    return len(x.src)\n","\n","BATCH_SIZE = 64\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE, \n","    device = device,\n","    sort_key=_len_sort_key\n",")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"S6ZK7gmzFdLD","executionInfo":{"status":"ok","timestamp":1626354183593,"user_tz":-180,"elapsed":3,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["class Encoder_LSTM(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.LSTM = nn.LSTM(emb_dim, enc_hid_dim, bidirectional = True, num_layers=2)\n","\n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        \n","        self.fc_2 = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):\n","        \n","        #src = [src len, batch size]\n","        embedded = self.dropout(self.embedding(src))\n","        #embedded = [src len, batch size, emb dim]\n","        \n","        outputs, (hidden, cell) = self.LSTM(embedded)\n","        #outputs = [src len, batch size, hid dim * num directions]\n","        #hidden = [n layers * num directions, batch size, hid dim]\n","        #cell = [n layers, batch size, hid dim]\n","\n","        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n","        #outputs are always from the last layer\n","        #hidden [-2, :, : ] is the last of the forwards RNN \n","        #hidden [-1, :, : ] is the last of the backwards RNN\n","        \n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","        cell = torch.tanh(self.fc_2(torch.cat((cell[-2,:,:], cell[-1,:,:]), dim=1)))\n","        #outputs = [src len, batch size, enc hid dim * 2]\n","        #hidden = [batch size, dec hid dim]\n","        #cell = [n layers, batch size, hid dim]\n","        return outputs, hidden, cell"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_EmVty2-t1K","executionInfo":{"status":"ok","timestamp":1626354186974,"user_tz":-180,"elapsed":229,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["def temp_softmax(x, dim=0, temperature=1):\n","    e_x = torch.exp(x / temperature)\n","    return e_x/torch.sum(e_x, dim=0)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ej0JEiBhFe8S","executionInfo":{"status":"ok","timestamp":1626354188825,"user_tz":-180,"elapsed":235,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["class Attention_LSTM(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        \n","        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n","        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n","        \n","    def forward(self, hidden, encoder_outputs):\n","        \n","        #hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n","        \n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        \n","        hidden = hidden.unsqueeze(1)\n","        #hidden = [batch size, 1, dec hid dim]\n","\n","        hidden = hidden.repeat(1, src_len, 1)\n","        #hidden = [batch size, src len, dec hid dim]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n","\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n","        #energy = [batch size, src len, dec hid dim]\n","\n","        attention = self.v(energy).squeeze(2)\n","        #attention = [batch size, src len]\n","        \n","        return temp_softmax(attention, dim=1)"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AE93iWzFgps","executionInfo":{"status":"ok","timestamp":1626354205618,"user_tz":-180,"elapsed":242,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["class Decoder_LSTM(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        self.LSTM = nn.LSTM((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","\n","        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, cell, encoder_outputs):\n","             \n","        #input = [batch size]\n","        #hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n","        \n","        input = input.unsqueeze(0)\n","        #input = [1, batch size]\n","        \n","        embedded = self.dropout(self.embedding(input))\n","        #embedded = [1, batch size, emb dim]\n","        \n","        a = self.attention(hidden, encoder_outputs)\n","        #a = [batch size, src len]\n","        a = a.unsqueeze(1)\n","        #a = [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)\n","        #weighted = [batch size, 1, enc hid dim * 2]\n","        weighted = weighted.permute(1, 0, 2)\n","        #weighted = [1, batch size, enc hid dim * 2]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n","        hidden = hidden.unsqueeze(0)\n","        #hidden = [1, batch size, dec hid dim]\n","        cell = cell.unsqueeze(0)\n","        #cell = [1, batch size, dec hid dim]\n","\n","        output, (hidden, cell) = self.LSTM(rnn_input, (hidden, cell))\n","        #output = [seq len, batch size, dec hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, dec hid dim]\n","        #cell = [n layers * n directions, batch size, dec hid dim]\n","\n","        #seq len, n layers and n directions will be 1\n","        #output = [1, batch size, dec hid dim]\n","        #hidden = [1, batch size, dec hid dim]\n","        #cell = [1, batch size, dec hid dim]\n","\n","        embedded = embedded.squeeze(0)\n","        #embedded = [batch size, emb dim]\n","        output = output.squeeze(0)\n","        #output = [batch size, dec hid dim]\n","        weighted = weighted.squeeze(0)\n","        #weighted = [batch size, enc hid dim * 2]\n","        hidden = hidden.squeeze(0)\n","        #hidden = [batch size, dec hid dim]\n","        cell = cell.squeeze(0)\n","        #cell = [batch size, dec hid dim]\n","\n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden, cell"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"srCeveD9FjPT","executionInfo":{"status":"ok","timestamp":1626354206553,"user_tz":-180,"elapsed":6,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["class Translator_LSTM(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    def forward(self, src, trg, teacher_forcing):\n","        \n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        \n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #encoder_outputs is all hidden states of the input sequence, back and forwards\n","        #hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, hidden, cell = self.encoder(src)\n","                \n","        #first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden state and all encoder hidden states\n","            #receive output tensor (predictions) and new hidden state\n","            output, hidden, cell = self.decoder(input, hidden, cell, encoder_outputs)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vb-qRYjKFvQL","executionInfo":{"status":"ok","timestamp":1626354221731,"user_tz":-180,"elapsed":12142,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["input_dim = len(SRC.vocab)\n","output_dim = len(TRG.vocab)\n","encoder_embedding_dim = 256\n","decoder_embedding_dim = 256\n","encoder_hidden_dim = 512\n","decoder_hidden_dim = 512\n","encoder_dropout_prob = 0.5\n","decoder_dropout_prob = 0.5\n","\n","attention = Attention_LSTM(encoder_hidden_dim, decoder_hidden_dim)\n","encoder = Encoder_LSTM(input_dim, encoder_embedding_dim, encoder_hidden_dim, \n","                      decoder_hidden_dim, encoder_dropout_prob)\n","decoder = Decoder_LSTM(output_dim, decoder_embedding_dim, encoder_hidden_dim, \n","                      decoder_hidden_dim, decoder_dropout_prob, attention)\n","\n","model = Translator_LSTM(encoder, decoder, device).to(device)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGck3CE7Fvtv","executionInfo":{"status":"ok","timestamp":1626354227018,"user_tz":-180,"elapsed":239,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"f3dbae44-f4ca-47dd-be10-7ec3c6ca1073"},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(init_weights)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Translator_LSTM(\n","  (encoder): Encoder_LSTM(\n","    (embedding): Embedding(11778, 256)\n","    (LSTM): LSTM(256, 512, num_layers=2, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=512, bias=True)\n","    (fc_2): Linear(in_features=1024, out_features=512, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder_LSTM(\n","    (attention): Attention_LSTM(\n","      (attn): Linear(in_features=1536, out_features=512, bias=True)\n","      (v): Linear(in_features=512, out_features=1, bias=False)\n","    )\n","    (embedding): Embedding(16483, 256)\n","    (LSTM): LSTM(1280, 512)\n","    (fc_out): Linear(in_features=1792, out_features=16483, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix-OaNqJF0lS","executionInfo":{"status":"ok","timestamp":1626354233058,"user_tz":-180,"elapsed":291,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}},"outputId":"4817eb71-7700-488c-b92e-ef34ac8267d3"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":26,"outputs":[{"output_type":"stream","text":["The model has 51,753,571 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XZlagVR36Jfr","executionInfo":{"status":"ok","timestamp":1626354236294,"user_tz":-180,"elapsed":237,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["def delete_eos(tokens_iter):\n","    for token in tokens_iter:\n","        if token == '<eos>':\n","            break\n","        yield token\n","\n","def remove_tech_tokens(tokens_iter, tokens_to_remove=['<sos>', '<unk>', '<pad>']):\n","    return [x for x in tokens_iter if x not in tokens_to_remove]\n","\n","def generate_translation(src, trg, model, TRG_vocab):\n","    model.eval()\n","    # запускаем без teacher_forcing\n","    output = model(src, trg, 0)\n","    # удаляем первый токен и выбираем лучшее слово\n","    output = output[1:].argmax(-1)\n","    #print(output)\n","    original = remove_tech_tokens(delete_eos([TRG_vocab.itos[x] for x in list(trg[:,0].cpu().numpy())]))\n","    generated = remove_tech_tokens(delete_eos([TRG_vocab.itos[x] for x in list(output[:, 0].cpu().numpy())]))\n","    \n","    print('Правильный перевод: {}'.format(' '.join(original)))\n","    print('Перевод модели: {}'.format(' '.join(generated)))\n","\n","def get_text(x, TRG_vocab):\n","     generated = remove_tech_tokens(delete_eos([TRG_vocab.itos[elem] for elem in list(x)]))\n","     return generated\n","\n","from nltk.translate.bleu_score import corpus_bleu\n","\n","def get_bleu(iterator):\n","    original_text = []\n","    generated_text = []\n","    model.eval()\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src = batch.src\n","            trg = batch.trg\n","            # запускаем без teacher_forcing\n","            output = model(src, trg, 0)\n","            # удаляем первый токен и выбираем лучшее слово\n","            output = output[1:].argmax(-1)\n","            # собираем данные для подсчета BLEU\n","            original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n","            generated_text.extend([get_text(x, TRG.vocab) for x in output.detach().cpu().numpy().T])\n","    bleu = corpus_bleu([[text] for text in original_text], generated_text) * 100\n","    return bleu"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"07P2alGqF5kL","executionInfo":{"status":"ok","timestamp":1626354238085,"user_tz":-180,"elapsed":229,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["optimizer = optim.Adam(model.parameters())\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBrC6YI-F5_7","executionInfo":{"status":"ok","timestamp":1626354264291,"user_tz":-180,"elapsed":229,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiI7RhsRu1aZRys7R5PxUx10vTA1GY1JB3IF4y3dQ=s64","userId":"08391319538016968223"}}},"source":["def train(model, iterator, optimizer, criterion, clip, epoch):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        teacher_forcing = 1 - epoch * 0.25\n","        if teacher_forcing < 0.6:\n","            teacher_forcing = 0.6\n","        output = model(src, trg, teacher_forcing = teacher_forcing)\n","        \n","        #trg = [trg len, batch size]\n","        #output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg len - 1) * batch size]\n","        #output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n","\n","def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, trg, 0) #turn off teacher forcing\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"nv14Sr_MGBAC","colab":{"base_uri":"https://localhost:8080/","height":327,"referenced_widgets":["6e7ddad4551e411ebc7022e220710b71","491145053af84ce18d2cabedca49280f","b744bc65c968419dbf507b156357dd89","212cc8cd1a9f4894b11d56329341c8e1","34a534950fd64acf8b9684245b5623cf","f77274caad944d61bd831b8f9271804b","f316e3a790204517a1742cdeccb297e2","c6bded63dbc143bc8055404e36dffe04"]},"outputId":"4e9122d5-36f1-40ec-8072-782a23f14372"},"source":["epochs = 10\n","clip = 1\n","\n","best_valid_loss = float('inf')\n","best_valid_bleu = 0\n","for epoch in tqdm.notebook.tqdm(range(epochs)):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, clip, epoch)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    valid_bleu = get_bleu(test_iterator)\n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/NLP/attention_LSTM_en_ru.pt')\n","    if valid_bleu > best_valid_bleu:\n","        best_valid_bleu= valid_bleu\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/NLP/attention_LSTM_bleu_en_ru.pt')\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","    print(f'\\t Val. BLEU: {valid_bleu:.3f}')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6e7ddad4551e411ebc7022e220710b71","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch: 01 | Time: 7m 44s\n","\tTrain Loss: 4.120 | Train PPL:  61.554\n","\t Val. Loss: 8.688 |  Val. PPL: 5934.253\n","\t Val. BLEU: 0.448\n","Epoch: 02 | Time: 7m 47s\n","\tTrain Loss: 3.550 | Train PPL:  34.823\n","\t Val. Loss: 8.268 |  Val. PPL: 3898.709\n","\t Val. BLEU: 0.159\n","Epoch: 03 | Time: 7m 47s\n","\tTrain Loss: 3.680 | Train PPL:  39.660\n","\t Val. Loss: 7.262 |  Val. PPL: 1425.540\n","\t Val. BLEU: 2.504\n","Epoch: 04 | Time: 7m 49s\n","\tTrain Loss: 3.459 | Train PPL:  31.773\n","\t Val. Loss: 7.209 |  Val. PPL: 1352.119\n","\t Val. BLEU: 4.095\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SN05PGwDaMbV"},"source":["torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/NLP/attention_LSTM_last_en_ru.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2w7Iso5JQPKT"},"source":["model_name = 'attention_LSTM_bleu_en_ru.pt'\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/NLP/' + model_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHVQDTWoQcjz"},"source":["def translate_batch(iterator):\n","    batch = next(iter(iterator))\n","    for idx in range(10):\n","        src = batch.src[:, idx:idx+1]\n","        trg = batch.trg[:, idx:idx+1]\n","        generate_translation(src, trg, model, TRG.vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5R9l-le7l_ik"},"source":["translate_batch(test_iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"d7UI_gK5QLBz"},"source":["print(\"Train BLEU = \",get_bleu(train_iterator))\n","print(\"Valid BLEU = \",get_bleu(valid_iterator))\n","print(\"Test BLEU = \",get_bleu(test_iterator))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lsyvwQ7u09-0"},"source":["def translate(data):\n","    with open('example.txt', 'w') as file:\n","        file.write(str(data*2+','+data))\n","    test_dataset = torchtext.legacy.data.TabularDataset(\n","        path='example.txt',\n","        format='csv',\n","        fields=[ ('src', SRC), ('trg', TRG)]\n","    )\n","    iterator = BucketIterator(\n","        test_dataset, \n","        batch_size = 1, \n","        device = device,\n","        sort_key=_len_sort_key\n","    )\n","    generated_text = []\n","    model.eval()\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src = batch.src\n","            trg = batch.trg\n","            # запускаем без teacher_forcing\n","            output = model(src, trg, 0)\n","            # удаляем первый токен и выбираем лучшее слово\n","            output = output[1:].argmax(-1)\n","            # собираем данные для подсчета BLEU\n","            generated_text.extend([get_text(x, TRG.vocab) for x in output.detach().cpu().numpy().T])\n","            generated_text=(' '.join(generated_text[0])[:-2]+'.').capitalize()\n","    translation = 'Перевод модели: {}'.format(generated_text)\n","    return translation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"V5VA_n7h8vkM","outputId":"aea4bde0-385b-43fd-f928-5b6b59e6b641"},"source":["data='На всей территории гостевого дома Jam работает бесплатный Wi-Fi.'\n","translate(data)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Перевод модели: Guesthouse features free wifi throughout the property.'"]},"metadata":{"tags":[]},"execution_count":83}]},{"cell_type":"code","metadata":{"id":"kje6Bed122id"},"source":[""],"execution_count":null,"outputs":[]}]}