{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Translation_Project_attention_GRU_en_ru.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"683236efe9ad4d83b38268cd1bce60dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9d8b3aa6678e4920b8ea11b152f36bc6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7d4ad107078b4ebfbec2006d2b106223","IPY_MODEL_927a7a505bbe4a9f85c7222a00dc2c36"]}},"9d8b3aa6678e4920b8ea11b152f36bc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7d4ad107078b4ebfbec2006d2b106223":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_50dc7e87e89e4b20958f0a5c8e94c87b","_dom_classes":[],"description":"  0%","_model_name":"FloatProgressModel","bar_style":"","max":10,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5afb612d12ef4ff2af7315077dd0dd40"}},"927a7a505bbe4a9f85c7222a00dc2c36":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d719e5d6ac4b4392928153ea42d6857b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/10 [00:00&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_5e5580f9fdbc429c9449053ee1e87cfd"}},"50dc7e87e89e4b20958f0a5c8e94c87b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"5afb612d12ef4ff2af7315077dd0dd40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d719e5d6ac4b4392928153ea42d6857b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"5e5580f9fdbc429c9449053ee1e87cfd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"i2Ko1khAESrf","executionInfo":{"status":"ok","timestamp":1626355548563,"user_tz":-180,"elapsed":8162,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import torchtext\n","from torchtext.legacy.data import Field, BucketIterator\n","\n","import spacy\n","from tqdm.notebook import tqdm\n","import tqdm\n","import random\n","import math\n","import time\n","import numpy as np\n","\n","import matplotlib\n","matplotlib.rcParams.update({'figure.figsize': (16, 12), 'font.size': 14})\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","from IPython.display import clear_output\n","\n","from nltk.tokenize import WordPunctTokenizer\n","from torch.nn import functional as F"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"yeyNXU5GQ-LJ","executionInfo":{"status":"ok","timestamp":1626355548567,"user_tz":-180,"elapsed":9,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["SEED = 666\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dvr0cndHF7od","executionInfo":{"status":"ok","timestamp":1626355550235,"user_tz":-180,"elapsed":16,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"b15e00ee-d554-4720-81ce-afb48a2c2edc"},"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","device"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CDopBvyWaXEQ","executionInfo":{"status":"ok","timestamp":1626355569532,"user_tz":-180,"elapsed":17643,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"3679239f-d9b9-4cba-f6e9-9d262364c6d7"},"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvHcv5trG8UU","executionInfo":{"status":"ok","timestamp":1626355571003,"user_tz":-180,"elapsed":1477,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"a9d5e48a-91c5-41c6-c598-85f1044854f7"},"source":["!ls '/content/drive/MyDrive/Colab Notebooks/NLP'"],"execution_count":5,"outputs":[{"output_type":"stream","text":["attention_GRU_bleu.pt  Translation_Project_attention_GRU_en_ru.ipynb\n","attention_GRU_last.pt  Translation_Project_attention_GRU_ru_en.ipynb\n","attention_GRU.pt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rxi_ltKkKmw_","executionInfo":{"status":"ok","timestamp":1626355572307,"user_tz":-180,"elapsed":1326,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"bf0c62a2-b563-4c3a-d77a-88f317192999"},"source":["!wget https://drive.google.com/uc?id=1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_ -O data.txt"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2021-07-15 13:26:14--  https://drive.google.com/uc?id=1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_\n","Resolving drive.google.com (drive.google.com)... 108.177.97.113, 108.177.97.139, 108.177.97.101, ...\n","Connecting to drive.google.com (drive.google.com)|108.177.97.113|:443... connected.\n","HTTP request sent, awaiting response... 302 Moved Temporarily\n","Location: https://doc-14-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9jdcdaa8ncnjk7lf2i5e75hfv0pktfp4/1626355575000/16549096980415837553/*/1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_ [following]\n","Warning: wildcards not supported in HTTP.\n","--2021-07-15 13:26:15--  https://doc-14-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9jdcdaa8ncnjk7lf2i5e75hfv0pktfp4/1626355575000/16549096980415837553/*/1NWYqJgeG_4883LINdEjKUr6nLQPY6Yb_\n","Resolving doc-14-00-docs.googleusercontent.com (doc-14-00-docs.googleusercontent.com)... 74.125.203.132, 2404:6800:4008:c03::84\n","Connecting to doc-14-00-docs.googleusercontent.com (doc-14-00-docs.googleusercontent.com)|74.125.203.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: unspecified [text/plain]\n","Saving to: ‘data.txt’\n","\n","data.txt                [ <=>                ]  12.31M  63.6MB/s    in 0.2s    \n","\n","2021-07-15 13:26:16 (63.6 MB/s) - ‘data.txt’ saved [12905334]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jDbsLi5YJq9P","executionInfo":{"status":"ok","timestamp":1626355576713,"user_tz":-180,"elapsed":538,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["tokenizer_W = WordPunctTokenizer()\n","\n","def tokenize_ru(x, tokenizer=WordPunctTokenizer()):\n","    return tokenizer.tokenize(x.lower())\n","\n","def tokenize_en(x, tokenizer=WordPunctTokenizer()):\n","    return tokenizer.tokenize(x.lower())"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"uxjRcQAbJwwI","executionInfo":{"status":"ok","timestamp":1626355581195,"user_tz":-180,"elapsed":2698,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["SRC = Field(tokenize=tokenize_ru,\n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","TRG = Field(tokenize=tokenize_en,\n","            init_token = '<sos>', \n","            eos_token = '<eos>', \n","            lower = True)\n","\n","\n","dataset = torchtext.legacy.data.TabularDataset(\n","    path='data.txt',\n","    format='tsv',\n","    fields=[('src', SRC), ('trg', TRG)]\n",")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHliJlHxJw9g","executionInfo":{"status":"ok","timestamp":1626355581196,"user_tz":-180,"elapsed":10,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"584d16db-dc77-40d4-bea0-fb7b2bb371e5"},"source":["print(len(dataset.examples))\n","print(dataset.examples[0].src)\n","print(dataset.examples[0].trg)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["50000\n","['cordelia', 'hotel', 'is', 'situated', 'in', 'tbilisi', ',', 'a', '3', '-', 'minute', 'walk', 'away', 'from', 'saint', 'trinity', 'church', '.']\n","['отель', 'cordelia', 'расположен', 'в', 'тбилиси', ',', 'в', '3', 'минутах', 'ходьбы', 'от', 'свято', '-', 'троицкого', 'собора', '.']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ITHVChNxLAe-","executionInfo":{"status":"ok","timestamp":1626355582930,"user_tz":-180,"elapsed":8,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"e9b08927-4faa-46ac-efac-c54be7d1a6c4"},"source":["train_data, valid_data, test_data = dataset.split(split_ratio=[0.8, 0.15, 0.05])\n","\n","print(f\"Number of training examples: {len(train_data.examples)}\")\n","print(f\"Number of validation examples: {len(valid_data.examples)}\")\n","print(f\"Number of testing examples: {len(test_data.examples)}\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Number of training examples: 40000\n","Number of validation examples: 2500\n","Number of testing examples: 7500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nFgcavqGLHT-","executionInfo":{"status":"ok","timestamp":1626355586437,"user_tz":-180,"elapsed":1200,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["SRC.build_vocab(dataset, min_freq = 2)\n","TRG.build_vocab(dataset, min_freq = 2)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mgPWlOaHLI_v","executionInfo":{"status":"ok","timestamp":1626355608759,"user_tz":-180,"elapsed":389,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"c935836c-5d3b-4023-c3b9-34f4f264059c"},"source":["print(f\"Unique tokens in source (en) vocabulary: {len(SRC.vocab)}\")\n","print(f\"Unique tokens in target (ru) vocabulary: {len(TRG.vocab)}\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Unique tokens in source (en) vocabulary: 11778\n","Unique tokens in target (ru) vocabulary: 16483\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dq_JbomULJMv","executionInfo":{"status":"ok","timestamp":1626355611493,"user_tz":-180,"elapsed":363,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"3fc7e04e-801d-4148-9ad0-8750f988f904"},"source":["print(vars(train_data.examples[9]))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["{'src': ['there', 'is', 'a', 'concierge', 'service', 'and', '24', '-', 'hour', 'front', 'desk', '.'], 'trg': ['гостям', 'предоставляются', 'услуги', 'консьержа', 'и', 'круглосуточной', 'стойки', 'регистрации', '.']}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Peyv-N1dLNaO","executionInfo":{"status":"ok","timestamp":1626355615531,"user_tz":-180,"elapsed":496,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["def _len_sort_key(x):\n","    return len(x.src)\n","\n","BATCH_SIZE = 64\n","\n","train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","    (train_data, valid_data, test_data), \n","    batch_size = BATCH_SIZE, \n","    device = device,\n","    sort_key=_len_sort_key\n",")"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"S6ZK7gmzFdLD","executionInfo":{"status":"ok","timestamp":1626355617840,"user_tz":-180,"elapsed":377,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["class Encoder_GRU(nn.Module):\n","    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\n","        super().__init__()\n","        \n","        self.embedding = nn.Embedding(input_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n","        \n","        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, src):\n","        \n","        #src = [src len, batch size]\n","        embedded = self.dropout(self.embedding(src))\n","        #embedded = [src len, batch size, emb dim]\n","        \n","        outputs, hidden = self.rnn(embedded)     \n","        #outputs = [src len, batch size, hid dim * num directions]\n","        #hidden = [n layers * num directions, batch size, hid dim]\n","        \n","        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n","        #outputs are always from the last layer\n","        \n","        #hidden [-2, :, : ] is the last of the forwards RNN \n","        #hidden [-1, :, : ] is the last of the backwards RNN\n","        \n","        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n","        #outputs = [src len, batch size, enc hid dim * 2]\n","        #hidden = [batch size, dec hid dim]\n","        \n","        return outputs, hidden"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ej0JEiBhFe8S","executionInfo":{"status":"ok","timestamp":1626355619989,"user_tz":-180,"elapsed":4,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["class Attention_GRU(nn.Module):\n","    def __init__(self, enc_hid_dim, dec_hid_dim):\n","        super().__init__()\n","        \n","        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n","        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n","        \n","    def forward(self, hidden, encoder_outputs):\n","        \n","        #hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n","        \n","        batch_size = encoder_outputs.shape[1]\n","        src_len = encoder_outputs.shape[0]\n","        \n","        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n","        #hidden = [batch size, src len, dec hid dim]\n","\n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n","\n","        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n","        #energy = [batch size, src len, dec hid dim]\n","\n","        attention = self.v(energy).squeeze(2)\n","        #attention = [batch size, src len]\n","        \n","        return F.softmax(attention, dim=1)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"6AE93iWzFgps","executionInfo":{"status":"ok","timestamp":1626355621920,"user_tz":-180,"elapsed":4,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["class Decoder_GRU(nn.Module):\n","    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n","        super().__init__()\n","\n","        self.output_dim = output_dim\n","        self.attention = attention\n","        \n","        self.embedding = nn.Embedding(output_dim, emb_dim)\n","        \n","        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n","        \n","        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n","        \n","        self.dropout = nn.Dropout(dropout)\n","        \n","    def forward(self, input, hidden, encoder_outputs):\n","             \n","        #input = [batch size]\n","        #hidden = [batch size, dec hid dim]\n","        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n","        \n","        input = input.unsqueeze(0)\n","        #input = [1, batch size]\n","        embedded = self.dropout(self.embedding(input))\n","        #embedded = [1, batch size, emb dim]\n","        \n","        a = self.attention(hidden, encoder_outputs)  \n","        #a = [batch size, src len]\n","        a = a.unsqueeze(1)\n","        #a = [batch size, 1, src len]\n","        \n","        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n","        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n","        \n","        weighted = torch.bmm(a, encoder_outputs)\n","        #weighted = [batch size, 1, enc hid dim * 2]\n","        \n","        weighted = weighted.permute(1, 0, 2)\n","        #weighted = [1, batch size, enc hid dim * 2]\n","        \n","        rnn_input = torch.cat((embedded, weighted), dim = 2)\n","        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n","            \n","        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n","        #output = [seq len, batch size, dec hid dim * n directions]\n","        #hidden = [n layers * n directions, batch size, dec hid dim]\n","        \n","        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n","        #output = [1, batch size, dec hid dim]\n","        #hidden = [1, batch size, dec hid dim]\n","        \n","        embedded = embedded.squeeze(0)\n","        output = output.squeeze(0)\n","        weighted = weighted.squeeze(0)\n","        \n","        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n","        \n","        #prediction = [batch size, output dim]\n","        \n","        return prediction, hidden.squeeze(0)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"srCeveD9FjPT","executionInfo":{"status":"ok","timestamp":1626355673899,"user_tz":-180,"elapsed":424,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["class Translator_GRU(nn.Module):\n","    def __init__(self, encoder, decoder, device):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.device = device\n","        \n","    def forward(self, src, trg, teacher_forcing):\n","        \n","        #src = [src len, batch size]\n","        #trg = [trg len, batch size]\n","        \n","        batch_size = src.shape[1]\n","        trg_len = trg.shape[0]\n","        trg_vocab_size = self.decoder.output_dim\n","        \n","        #tensor to store decoder outputs\n","        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n","        \n","        #encoder_outputs is all hidden states of the input sequence, back and forwards\n","        #hidden is the final forward and backward hidden states, passed through a linear layer\n","        encoder_outputs, hidden = self.encoder(src)\n","                \n","        #first input to the decoder is the <sos> tokens\n","        input = trg[0,:]\n","        \n","        for t in range(1, trg_len):\n","            \n","            #insert input token embedding, previous hidden state and all encoder hidden states\n","            #receive output tensor (predictions) and new hidden state\n","            output, hidden = self.decoder(input, hidden, encoder_outputs)\n","            \n","            #place predictions in a tensor holding predictions for each token\n","            outputs[t] = output\n","            \n","            #decide if we are going to use teacher forcing or not\n","            teacher_force = random.random() < teacher_forcing\n","            \n","            #get the highest predicted token from our predictions\n","            top1 = output.argmax(1) \n","            \n","            #if teacher forcing, use actual next token as next input\n","            #if not, use predicted token\n","            input = trg[t] if teacher_force else top1\n","\n","        return outputs"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"Vb-qRYjKFvQL","executionInfo":{"status":"ok","timestamp":1626355676087,"user_tz":-180,"elapsed":607,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["input_dim = len(SRC.vocab)\n","output_dim = len(TRG.vocab)\n","encoder_embedding_dim = 256\n","decoder_embedding_dim = 256\n","encoder_hidden_dim = 512\n","decoder_hidden_dim = 512\n","encoder_dropout_prob = 0.5\n","decoder_dropout_prob = 0.5\n","\n","attention = Attention_GRU(encoder_hidden_dim, decoder_hidden_dim)\n","encoder = Encoder_GRU(input_dim, encoder_embedding_dim, encoder_hidden_dim, \n","                      decoder_hidden_dim, encoder_dropout_prob)\n","decoder = Decoder_GRU(output_dim, decoder_embedding_dim, encoder_hidden_dim, \n","                      decoder_hidden_dim, decoder_dropout_prob, attention)\n","\n","model = Translator_GRU(encoder, decoder, device).to(device)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FGck3CE7Fvtv","executionInfo":{"status":"ok","timestamp":1626355677387,"user_tz":-180,"elapsed":18,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"1d25f602-e5f3-43ad-83be-6fd5f95796b3"},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        if 'weight' in name:\n","            nn.init.normal_(param.data, mean=0, std=0.01)\n","        else:\n","            nn.init.constant_(param.data, 0)\n","            \n","model.apply(init_weights)"],"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Translator_GRU(\n","  (encoder): Encoder_GRU(\n","    (embedding): Embedding(11778, 256)\n","    (rnn): GRU(256, 512, bidirectional=True)\n","    (fc): Linear(in_features=1024, out_features=512, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n","  (decoder): Decoder_GRU(\n","    (attention): Attention_GRU(\n","      (attn): Linear(in_features=1536, out_features=512, bias=True)\n","      (v): Linear(in_features=512, out_features=1, bias=False)\n","    )\n","    (embedding): Embedding(16483, 256)\n","    (rnn): GRU(1280, 512)\n","    (fc_out): Linear(in_features=1792, out_features=16483, bias=True)\n","    (dropout): Dropout(p=0.5, inplace=False)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ix-OaNqJF0lS","executionInfo":{"status":"ok","timestamp":1626355678742,"user_tz":-180,"elapsed":13,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}},"outputId":"f8808aba-c599-445a-e259-7c5b224d87c8"},"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","print(f'The model has {count_parameters(model):,} trainable parameters')"],"execution_count":29,"outputs":[{"output_type":"stream","text":["The model has 43,222,115 trainable parameters\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XZlagVR36Jfr","executionInfo":{"status":"ok","timestamp":1626355680139,"user_tz":-180,"elapsed":7,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["def delete_eos(tokens_iter):\n","    for token in tokens_iter:\n","        if token == '<eos>':\n","            break\n","        yield token\n","\n","def remove_tech_tokens(tokens_iter, tokens_to_remove=['<sos>', '<unk>', '<pad>']):\n","    return [x for x in tokens_iter if x not in tokens_to_remove]\n","\n","def generate_translation(src, trg, model, TRG_vocab):\n","    model.eval()\n","    # запускаем без teacher_forcing\n","    output = model(src, trg, 0)\n","    # удаляем первый токен и выбираем лучшее слово\n","    output = output[1:].argmax(-1)\n","    #print(output)\n","    original = remove_tech_tokens(delete_eos([TRG_vocab.itos[x] for x in list(trg[:,0].cpu().numpy())]))\n","    generated = remove_tech_tokens(delete_eos([TRG_vocab.itos[x] for x in list(output[:, 0].cpu().numpy())]))\n","    \n","    print('Правильный перевод: {}'.format(' '.join(original)))\n","    print('Перевод модели: {}'.format(' '.join(generated)))\n","\n","def get_text(x, TRG_vocab):\n","     generated = remove_tech_tokens(delete_eos([TRG_vocab.itos[elem] for elem in list(x)]))\n","     return generated\n","\n","from nltk.translate.bleu_score import corpus_bleu\n","\n","def get_bleu(iterator):\n","    original_text = []\n","    generated_text = []\n","    model.eval()\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src = batch.src\n","            trg = batch.trg\n","            # запускаем без teacher_forcing\n","            output = model(src, trg, 0)\n","            # удаляем первый токен и выбираем лучшее слово\n","            output = output[1:].argmax(-1)\n","            # собираем данные для подсчета BLEU\n","            original_text.extend([get_text(x, TRG.vocab) for x in trg.cpu().numpy().T])\n","            generated_text.extend([get_text(x, TRG.vocab) for x in output.detach().cpu().numpy().T])\n","    bleu = corpus_bleu([[text] for text in original_text], generated_text) * 100\n","    return bleu"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"07P2alGqF5kL","executionInfo":{"status":"ok","timestamp":1626355681778,"user_tz":-180,"elapsed":5,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["optimizer = optim.Adam(model.parameters())\n","TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n","criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"OBrC6YI-F5_7","executionInfo":{"status":"ok","timestamp":1626355683237,"user_tz":-180,"elapsed":4,"user":{"displayName":"Владимир Терентьев","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjyuskRcO4tcAtA7V9V7iW7Cq6HgT67F7K30gVVjA=s64","userId":"08391753862884812694"}}},"source":["def train(model, iterator, optimizer, criterion, clip, epoch):\n","    \n","    model.train()\n","    \n","    epoch_loss = 0\n","    \n","    for i, batch in enumerate(iterator):\n","        \n","        src = batch.src\n","        trg = batch.trg\n","        \n","        optimizer.zero_grad()\n","        teacher_forcing = 1 - epoch * 0.25\n","        if teacher_forcing < 0.6:\n","            teacher_forcing = 0.6\n","        output = model(src, trg, teacher_forcing = teacher_forcing)\n","        \n","        #trg = [trg len, batch size]\n","        #output = [trg len, batch size, output dim]\n","        \n","        output_dim = output.shape[-1]\n","        \n","        output = output[1:].view(-1, output_dim)\n","        trg = trg[1:].view(-1)\n","        \n","        #trg = [(trg len - 1) * batch size]\n","        #output = [(trg len - 1) * batch size, output dim]\n","        \n","        loss = criterion(output, trg)\n","        loss.backward()\n","        \n","        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n","        \n","        optimizer.step()\n","        \n","        epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n","\n","def evaluate(model, iterator, criterion):\n","    \n","    model.eval()\n","    \n","    epoch_loss = 0\n","    \n","    with torch.no_grad():\n","    \n","        for i, batch in enumerate(iterator):\n","\n","            src = batch.src\n","            trg = batch.trg\n","\n","            output = model(src, trg, 0) #turn off teacher forcing\n","\n","            #trg = [trg len, batch size]\n","            #output = [trg len, batch size, output dim]\n","\n","            output_dim = output.shape[-1]\n","            \n","            output = output[1:].view(-1, output_dim)\n","            trg = trg[1:].view(-1)\n","\n","            #trg = [(trg len - 1) * batch size]\n","            #output = [(trg len - 1) * batch size, output dim]\n","\n","            loss = criterion(output, trg)\n","\n","            epoch_loss += loss.item()\n","        \n","    return epoch_loss / len(iterator)\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"nv14Sr_MGBAC","colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["683236efe9ad4d83b38268cd1bce60dd","9d8b3aa6678e4920b8ea11b152f36bc6","7d4ad107078b4ebfbec2006d2b106223","927a7a505bbe4a9f85c7222a00dc2c36","50dc7e87e89e4b20958f0a5c8e94c87b","5afb612d12ef4ff2af7315077dd0dd40","d719e5d6ac4b4392928153ea42d6857b","5e5580f9fdbc429c9449053ee1e87cfd"]},"outputId":"7a0edcd2-3879-439d-956b-23feef4d2377"},"source":["epochs = 10\n","clip = 1\n","\n","best_valid_loss = float('inf')\n","best_valid_bleu = 0\n","for epoch in tqdm.notebook.tqdm(range(epochs)):\n","    \n","    start_time = time.time()\n","    \n","    train_loss = train(model, train_iterator, optimizer, criterion, clip, epoch)\n","    valid_loss = evaluate(model, valid_iterator, criterion)\n","    valid_bleu = get_bleu(test_iterator)\n","    end_time = time.time()\n","    \n","    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","    \n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/NLP/attention_GRU_en_ru.pt')\n","    if valid_bleu > best_valid_bleu:\n","        best_valid_bleu= valid_bleu\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/NLP/attention_GRU_bleu_en_ru.pt')\n","    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n","    print(f'\\t Val. BLEU: {valid_bleu:.3f}')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"683236efe9ad4d83b38268cd1bce60dd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"SN05PGwDaMbV"},"source":["torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/NLP/attention_GRU_last_en_ru.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5R9l-le7l_ik"},"source":["model_name = 'attention_GRU_bleu_en_ru.pt'\n","model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/NLP/' + model_name))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1zHRsNnXn60b"},"source":["def translate_batch(iterator):\n","    batch = next(iter(iterator))\n","    for idx in range(10):\n","        src = batch.src[:, idx:idx+1]\n","        trg = batch.trg[:, idx:idx+1]\n","        generate_translation(src, trg, model, TRG.vocab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1YzM166hXQwh"},"source":["translate_batch(test_iterator)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KAuyyUt_XSEA"},"source":["print(\"Train BLEU = \",get_bleu(train_iterator))\n","print(\"Valid BLEU = \",get_bleu(valid_iterator))\n","print(\"Test BLEU = \",get_bleu(test_iterator))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_Geub0AXTrZ"},"source":["def translate(data):\n","    with open('example.txt', 'w') as file:\n","        file.write(str(data*2+','+data))\n","    test_dataset = torchtext.legacy.data.TabularDataset(\n","        path='example.txt',\n","        format='csv',\n","        fields=[('src', SRC), ('trg', TRG)]\n","    )\n","    iterator = BucketIterator(\n","        test_dataset, \n","        batch_size = 1, \n","        device = device,\n","        sort_key=_len_sort_key\n","    )\n","    generated_text = []\n","    model.eval()\n","    with torch.no_grad():\n","        for i, batch in enumerate(iterator):\n","            src = batch.src\n","            trg = batch.trg\n","            # запускаем без teacher_forcing\n","            output = model(src, trg, 0)\n","            # удаляем первый токен и выбираем лучшее слово\n","            output = output[1:].argmax(-1)\n","            # собираем данные для подсчета BLEU\n","            generated_text.extend([get_text(x, TRG.vocab) for x in output.detach().cpu().numpy().T])\n","            generated_text=(' '.join(generated_text[0])[:-2]+'.').capitalize()\n","    translation = 'Перевод модели: {}'.format(generated_text)\n","    return translation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q-YGWMVPXWTy"},"source":["data='laundry facilities are on site.'\n","translate(data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eNniIEzsWu8j"},"source":[""],"execution_count":null,"outputs":[]}]}